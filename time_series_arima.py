# -*- coding: utf-8 -*-
"""time_series_arima.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ejek21qZLEFsnilqeBNIilJVpnd-97sW
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import datetime
from pmdarima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX
import lightgbm as lgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from tensorflow import keras
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
import warnings
warnings.filterwarnings("ignore") # suppressing warnings

"""# Data Understanding: EDA

##Basic exploring
"""

df = pd.read_csv('train.csv')
df.head(10)

df["Order Date"]

# checking how many rows and columns in the dataset
df.shape

# getting more information from the data
df.info()

df.describe(include='all')

print(df['Category'].value_counts())
#print(df['Sub-Category'].value_counts())

"""## Check for Missing Values"""

missing_values = df.isnull().sum()
missing_values

"""##Check for Outliers"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='Category', y='Sales', data=df)
plt.title('Box Plot of Sales by Sub-Category')
plt.xlabel('Category')
plt.ylabel('Sales')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Sub-Category', y='Sales', data=df)
plt.title('Box Plot of Sales by Sub-Category')
plt.xlabel('Sub-Category')
plt.ylabel('Sales')
plt.xticks(rotation=90)
plt.show()

"""##Basic Analytic

###Customer Segmentation Analysis
"""

df.columns

features = df[['Segment','Country','City','State','Sales']]
top_10_sales = features.nlargest(10, 'Sales')
print('Top 10 Sales Revenue')
print(top_10_sales[['Segment','Country','City','State','Sales']])

segment_sales = df.groupby('Segment')['Sales'].sum().sort_values(ascending=False)
plt.figure(figsize=(20,6))
plt.subplot(1,3,1)
plt.subplot(1,3,1)
segment_sales.plot(kind='bar',color='green')
plt.title('Sales by Segment')
plt.xlabel('Segment')
plt.ylabel('Total Sales')
plt.show()

segment_sales = df.groupby('City')['Sales'].sum().sort_values(ascending=False).head(5)
plt.figure(figsize=(20,6))
plt.subplot(1,3,2)
segment_sales.plot(kind='bar',color='purple')
plt.title('Top 5 Cities Based on Sales')
plt.xlabel('City')
plt.ylabel('Total Sales')
plt.show()

segment_sales = df.groupby('State')['Sales'].sum().sort_values(ascending=False).head(5)
plt.figure(figsize=(20,6))
plt.subplot(1,3,3)
segment_sales.plot(kind='bar',color='lightgreen')
plt.title('Top 5 States Based on Sales')
plt.xlabel('State')
plt.ylabel('Total Sales')
plt.show()

heatmap_data = df.pivot_table(index='Segment', columns='Category', values='Sales', aggfunc='sum')
plt.figure(figsize=(10,6))
sns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt='.0f', cbar_kws={'label':'Total Sales'})
plt.title("Segment Sales by Product Category")
plt.show()

"""###Analyzing Order Fulfilment Efficiency"""

# converting into datetime object
df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')
df['Ship Date'] = pd.to_datetime(df['Ship Date'], format='%d/%m/%Y')
df['Processing Time'] = (df['Ship Date']- df['Order Date']).dt.days
median_processing_time =df.groupby('Sub-Category')['Processing Time'].median().sort_values()
print('Median Processing Time for each Product Sub-Category (days)')
print(median_processing_time)

"""###Analyzing Sales Performance Trend"""

# converting into datetime format
df['Order Date']= pd.to_datetime(df['Order Date'])
df['Year'] = df['Order Date'].dt.year

highest_selling_product = df.groupby(['Year', 'Category', 'Sub-Category'])['Sales'].sum().reset_index()

# Find the index of the row with the highest sales in each year
idx = highest_selling_product.groupby('Year')['Sales'].idxmax()

# Select the corresponding rows
highest_selling_product = highest_selling_product.loc[idx]

print('Best Performance Product Category and Sub Category for Each Year')
print(highest_selling_product[['Year', 'Category', 'Sub-Category', 'Sales']])

plt.figure(figsize=(12, 6))
sns.barplot(x='Year', y='Sales', hue='Sub-Category', data=highest_selling_product)
plt.title('Best Performing Product Sub Category for Each Year')
plt.xlabel('Product Sub-Category')
plt.ylabel('Sales Revenue')
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))
plt.show()

"""##Main Analytic

###Analysis of Sales Performance by Category Across Different Years
"""

df.head()

df.columns.tolist()

df['Year'].value_counts()

# Sales of each category of each years
category_sales_by_year = df.groupby(['Year', 'Category'])['Sales'].sum().reset_index()
print(category_sales_by_year)

category_sales_by_year = df.pivot_table(index='Year', columns='Category', values='Sales', aggfunc='sum').reset_index()

# Remove the "Category" name from the columns
category_sales_by_year.columns.name = None

print(category_sales_by_year)

import matplotlib.pyplot as plt
import numpy as np

# Set the width of the bars
bar_width = 0.2

# Set the positions of the bars on the x-axis
x = np.arange(len(category_sales_by_year['Year']))

# Create the bar plot
plt.bar(x - bar_width, category_sales_by_year['Furniture'], width=bar_width, label='Furniture', align='center')
plt.bar(x, category_sales_by_year['Office Supplies'], width=bar_width, label='Office Supplies', align='center')
plt.bar(x + bar_width, category_sales_by_year['Technology'], width=bar_width, label='Technology', align='center')

# Add labels and title
plt.xlabel('Year')
plt.ylabel('Sales')
plt.title('Sales by Category (2015-2018)')
plt.xticks(x, category_sales_by_year['Year'])  # Set the x-ticks to the years
plt.legend()  # Show the legend

# Show the plot
plt.tight_layout()
plt.show()

"""#Preprocessing

## Cleaning Dataset by Removing Missing Values & Duplicates
"""

print(df.isnull().sum().sort_values(ascending=False))

df.duplicated().any() # check if any duplicates exist in the dataframe

#delete column postal code
print("Before deleting the column", df.columns.tolist())
df.drop('Postal Code', axis=1, inplace=True)
print("After deleting the column", df.columns.tolist())

"""##Date Format Changing"""

df["Order Date"] = pd.to_datetime(df["Order Date"], format='%d/%m/%Y')
sorted_date = df["Order Date"].sort_values()
print(sorted_date)

df["Order Date"]

"""##Grouping the data"""

# Grouping the data and resetting the index
sales_by_category = df.groupby(["Category", df["Order Date"].dt.year])["Sales"].sum().reset_index()
print(sales_by_category)

"""##Spliting

Do in Model section

#2018 Sales Forecast

##Model + Model Evaluation
"""

import pandas as pd
from pmdarima import auto_arima
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

# Define a function to forecast sales for each category using ARIMA
def forecast_sales(category_data):
    # Set 'Order Date' as index and get the sales data
    sales_series = category_data.set_index("Order Date")["Sales"]

    # Split the data into training and validation sets with 80% training and 20% validation
    train_data, valid_data = train_test_split(sales_series, test_size=0.2, shuffle=False)

    # Fit the ARIMA model on the training data
    model = auto_arima(train_data, seasonal=True, suppress_warnings=True, stepwise=True)

    # Forecast for the validation period
    forecast_valid = model.predict(n_periods=len(valid_data))

    # Calculate MAE on the validation set
    mae = mean_absolute_error(valid_data, forecast_valid)

    # Now forecast for 2018 (1 period ahead)
    forecast_2018 = model.predict(n_periods=1)

    return pd.Series({
        "Category": category_data["Category"].iloc[0],
        "Forecasted_Sales_2018": forecast_2018.sum(),
        "MAE": mae
    })

# Apply the forecast_sales function to each category
forecasted_sales = sales_by_category.groupby("Category").apply(forecast_sales).reset_index(drop=True)

# Formatting the Forecasted_Sales_2018 column
forecasted_sales["Forecasted_Sales_2018"] = forecasted_sales["Forecasted_Sales_2018"].apply(lambda x: '{:,.2f}'.format(x))

# Displaying the result
print("Forecasted Sales in 2018 for Each Product Category:")
print(forecasted_sales[["Category", "Forecasted_Sales_2018", "MAE"]])

"""#2019 Sales Forecast"""

from pmdarima import auto_arima
sales_by_category = df.groupby(["Category", df["Order Date"].dt.year])["Sales"].sum().reset_index()

# Define a function to forecast sales for each category
def forecast_sales(category_data):
    sales_series = category_data.set_index("Order Date")["Sales"]
    model = auto_arima(sales_series, seasonal=True, suppress_warnings=True, stepwise=True)
    forecast = model.predict(n_periods=1)
    return pd.Series({
        "Category": category_data["Category"].iloc[0],
        "Forecasted_Sales_2019": forecast.sum()
    })

# Applying the forecast_sales function to each category group
forecasted_sales = sales_by_category.groupby("Category").apply(forecast_sales).reset_index(drop=True)

# Formatting the Forecasted_Sales_2019 column
forecasted_sales["Forecasted_Sales_2019"] = forecasted_sales["Forecasted_Sales_2019"].apply(lambda x: '{:,.2f}'.format(x))

# Displaying the result
print("Forecasted Sales in 2019 for Each Product Category:")
print(forecasted_sales[["Category", "Forecasted_Sales_2019"]])